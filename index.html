<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta content="Multi-Robot System Prototyping for Cooperative Control in Robot-Assisted Spine Surgery"
          name="description">
    <meta content="Robotics, cuRobo, markerless tracking" name="keywords">
    <meta content="width=device-width, initial-scale=1" name="viewport">
    <title>Multi-Robot System Prototyping for Cooperative Control in Robot-Assisted Spine Surgery</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
          dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link href="./static/css/bulma.min.css" rel="stylesheet">
    <link href="./static/css/bulma-carousel.min.css" rel="stylesheet">
    <link href="./static/css/bulma-slider.min.css" rel="stylesheet">
    <link href="./static/css/fontawesome.all.min.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
          rel="stylesheet">
    <link href="./static/css/index.css" rel="stylesheet">
    <link href="./static/images/favicon.svg" rel="icon">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>
<body>

<!--<nav class="navbar" role="navigation" aria-label="main navigation">-->
<!--  <div class="navbar-brand">-->
<!--    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">-->
<!--      <span aria-hidden="true"></span>-->
<!--      <span aria-hidden="true"></span>-->
<!--      <span aria-hidden="true"></span>-->
<!--    </a>-->
<!--  </div>-->
<!--  <div class="navbar-menu">-->
<!--    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">-->
<!--      <a class="navbar-item" href="https://keunhong.com">-->
<!--      <span class="icon">-->
<!--          <i class="fas fa-home"></i>-->
<!--      </span>-->
<!--      </a>-->

<!--      <div class="navbar-item has-dropdown is-hoverable">-->
<!--        <a class="navbar-link">-->
<!--          More Research-->
<!--        </a>-->
<!--        <div class="navbar-dropdown">-->
<!--          <a class="navbar-item" href="https://hypernerf.github.io">-->
<!--            HyperNeRF-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://nerfies.github.io">-->
<!--            Nerfies-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://latentfusion.github.io">-->
<!--            LatentFusion-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://photoshape.github.io">-->
<!--            PhotoShape-->
<!--          </a>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->

<!--  </div>-->
<!--</nav>-->


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">Multi-Robot System Prototyping for Cooperative Control in
                        Robot-Assisted Spine Surgery</h1>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">
                          <a href="https://shengyangzhuang.github.io/">Shengyang Zhuang</a><!--<sup>1</sup>-->,</span>
                                    <span class="author-block">
                          <a href="https://www.linkedin.com/in/connor-daly-595648114/">Connor Daly</a>,</span>
                                    <span class="author-block">
                          <a href="https://profiles.imperial.ac.uk/hisham.iqbal13">Hisham Iqbal</a>, and
                        </span>
                                    <span class="author-block">
                          <a href="https://profiles.imperial.ac.uk/f.rodriguez">Ferdinando Rodriguez y Baena</a>
                        </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block">Mechatronics in Medicine Lab, The Hamlyn Centre for Robotic Surgery, Imperial College London</span>
                        <!-- <span class="author-block"><sup>2</sup>Google Research</span> -->
                    </div>

<!--                    <div class="column has-text-centered">-->
<!--                        <div class="publication-links">-->
<!--                            &lt;!&ndash; PDF Link. &ndash;&gt;-->
<!--                            <span class="link-block">-->
<!--                                <a class="external-link button is-normal is-rounded is-dark"-->
<!--                                   href="https://arxiv.org/pdf/2011.12948">-->
<!--                                  <span class="icon">-->
<!--                                      <i class="fas fa-file-pdf"></i>-->
<!--                                  </span>-->
<!--                                  <span>Paper</span>-->
<!--                                </a>-->
<!--                            </span>-->
<!--                            <span class="link-block">-->
<!--                                <a class="external-link button is-normal is-rounded is-dark"-->
<!--                                   href="https://arxiv.org/abs/2011.12948">-->
<!--                                  <span class="icon">-->
<!--                                      <i class="ai ai-arxiv"></i>-->
<!--                                  </span>-->
<!--                                  <span>arXiv</span>-->
<!--                                </a>-->
<!--                            </span>-->
<!--                            &lt;!&ndash; Video Link. &ndash;&gt;-->
<!--                            <span class="link-block">-->
<!--                                <a class="external-link button is-normal is-rounded is-dark"-->
<!--                                   href="https://www.youtube.com/watch?v=MrKrnHhk8IA">-->
<!--                                  <span class="icon">-->
<!--                                      <i class="fab fa-youtube"></i>-->
<!--                                  </span>-->
<!--                                  <span>Video</span>-->
<!--                                </a>-->
<!--                            </span>-->
<!--                            &lt;!&ndash; Code Link. &ndash;&gt;-->
<!--                            <span class="link-block">-->
<!--                                <a class="external-link button is-normal is-rounded is-dark"-->
<!--                                   href="https://github.com/google/nerfies">-->
<!--                                  <span class="icon">-->
<!--                                      <i class="fab fa-github"></i>-->
<!--                                  </span>-->
<!--                                  <span>Code</span>-->
<!--                                  </a>-->
<!--                            </span>-->
<!--                            &lt;!&ndash; Dataset Link. &ndash;&gt;-->
<!--                            <span class="link-block">-->
<!--                                <a class="external-link button is-normal is-rounded is-dark"-->
<!--                                   href="https://github.com/google/nerfies/releases/tag/0.1">-->
<!--                                  <span class="icon">-->
<!--                                      <i class="far fa-images"></i>-->
<!--                                  </span>-->
<!--                                  <span>Data</span>-->
<!--                                  </a>-->
<!--                            </span>-->
<!--                        </div>-->

                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<!--<section class="hero teaser">-->
<!--  <div class="container is-max-desktop">-->
<!--    <div class="hero-body">-->
<!--      <video id="teaser" autoplay muted loop playsinline height="100%">-->
<!--        <source src="./static/videos/teaser.mp4"-->
<!--                type="video/mp4">-->
<!--      </video>-->
<!--      <h2 class="subtitle has-text-centered">-->
<!--        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into-->
<!--        free-viewpoint-->
<!--        portraits.-->
<!--      </h2>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->


<!--<section class="hero is-light is-small">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <div id="results-carousel" class="carousel results-carousel">-->
<!--        <div class="item item-steve">-->
<!--          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/steve.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-chair-tp">-->
<!--          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/chair-tp.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-shiba">-->
<!--          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/shiba.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-fullbody">-->
<!--          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/fullbody.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-blueshirt">-->
<!--          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/blueshirt.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-mask">-->
<!--          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/mask.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-coffee">-->
<!--          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/coffee.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-toby">-->
<!--          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/toby2.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->


<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Robot-assisted spine surgery has been clinically validated worldwide, demonstrating enhanced
                        performance, efficiency, and safety. However, current spine robotic systems rely on fiducial
                        markers, requiring additional incisions that increase the risk of infection. Additionally,
                        optical tracking systems are susceptible to line-of-sight obstructions. Previous research has
                        demonstrated limitations in simplifying obstacles as single points, making complex obstacle
                        environments unmanageable.
                    </p>
                    <p>
                        In this thesis, a multi-robot cooperative platform for surgery was developed, featuring a
                        plug-in to integrate a markerless depth image segmentation network for globally optimal
                        collision-free object tracking. The system enables a tracking robot arm to automatically adjust
                        its pose to maintain visual contact with a moving target, while the second surgical robot arm
                        acts as an obstacle. To achieve this, precise hand-eye calibration algorithms, including camera
                        calibration and ArUco marker detection, were developed with ROS2. Its accuracy was assessed in a
                        simulation environment before being tested on the real robot. The state-of-the-art cuRobo, a
                        GPU-accelerated motion planning library, was translated by developing ROS2 packages for highly
                        parallel inverse kinematics and trajectory optimization. Leveraging parallel computing enables
                        realizing a global optimal solution for obstacle avoidance. The motion-tracking performance of
                        the real robot on the generated trajectory was analyzed. Separate experiments and solve time
                        analyses were conducted for both simple and complex obstacle avoidance scenarios. The pipeline
                        was further developed into a continuous, efficient, collision-free object-tracking system. A
                        tracking performance analysis showed that the system generated near-optimal, smooth, and
                        collision-free paths. Finally, the algorithms were applied in a multi-robot marker tracking
                        experiment, with a demo showcasing markerless knee tracking through collision-free paths.
                    </p>
                    <!--                    <p>-->
                    <!--                        We show that <span class="dnerf">Nerfies</span> can turn casually captured selfie-->
                    <!--                        photos/videos into deformable NeRF-->
                    <!--                        models that allow for photorealistic renderings of the subject from arbitrary-->
                    <!--                        viewpoints, which we dub <i>"nerfies"</i>. We evaluate our method by collecting data-->
                    <!--                        using a-->
                    <!--                        rig with two mobile phones that take time-synchronized photos, yielding train/validation-->
                    <!--                        images of the same pose at different viewpoints. We show that our method faithfully-->
                    <!--                        reconstructs non-rigidly deforming scenes and reproduces unseen views with high-->
                    <!--                        fidelity.-->
                    <!--                    </p>-->
                </div>
            </div>
        </div>
        <!--/ Abstract. -->

        <!--        &lt;!&ndash; Paper video. &ndash;&gt;-->
        <!--        <div class="columns is-centered has-text-centered">-->
        <!--            <div class="column is-four-fifths">-->
        <!--                <h2 class="title is-3">Video</h2>-->
        <!--                <div class="publication-video">-->
        <!--                    <iframe allow="autoplay; encrypted-media"-->
        <!--                            allowfullscreen frameborder="0" src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"></iframe>-->
        <!--                </div>-->
        <!--            </div>-->
        <!--        </div>-->
        <!--        &lt;!&ndash;/ Paper video. &ndash;&gt;-->
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">

        <!--        <div class="columns is-centered">-->
        <!--            &lt;!&ndash; Visual Effects. &ndash;&gt;-->
        <!--            <div class="column">-->
        <!--                <div class="content">-->
        <!--                    <h2 class="title is-3">Visual Effects</h2>-->
        <!--                    <p>-->
        <!--                        Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect-->
        <!--                        would be impossible without nerfies since it would require going through a wall.-->
        <!--                    </p>-->
        <!--                    <video autoplay controls height="100%" id="dollyzoom" loop muted playsinline>-->
        <!--                        <source src="./static/videos/dollyzoom-stacked.mp4"-->
        <!--                                type="video/mp4">-->
        <!--                    </video>-->
        <!--                </div>-->
        <!--            </div>-->
        <!--            &lt;!&ndash;/ Visual Effects. &ndash;&gt;-->

        <!--            &lt;!&ndash; Matting. &ndash;&gt;-->
        <!--            <div class="column">-->
        <!--                <h2 class="title is-3">Matting</h2>-->
        <!--                <div class="columns is-centered">-->
        <!--                    <div class="column content">-->
        <!--                        <p>-->
        <!--                            As a byproduct of our method, we can also solve the matting problem by ignoring-->
        <!--                            samples that fall outside of a bounding box during rendering.-->
        <!--                        </p>-->
        <!--                        <video controls height="100%" id="matting-video" playsinline>-->
        <!--                            <source src="./static/videos/matting.mp4"-->
        <!--                                    type="video/mp4">-->
        <!--                        </video>-->
        <!--                    </div>-->

        <!--                </div>-->
        <!--            </div>-->
        <!--        </div>-->
        <!--        &lt;!&ndash;/ Matting. &ndash;&gt;-->

        <!-- Animation. -->
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h2 class="title is-3">Animation</h2>

                <!--                &lt;!&ndash; Interpolating. &ndash;&gt;-->
                <!--                <h3 class="title is-4">Interpolating states</h3>-->
                <!--                <div class="content has-text-justified">-->
                <!--                    <p>-->
                <!--                        We can also animate the scene by interpolating the deformation latent codes of two input-->
                <!--                        frames. Use the slider here to linearly interpolate between the left frame and the right-->
                <!--                        frame.-->
                <!--                    </p>-->
                <!--                </div>-->
                <!--                <div class="columns is-vcentered interpolation-panel">-->
                <!--                    <div class="column is-3 has-text-centered">-->
                <!--                        <img alt="Interpolate start reference image."-->
                <!--                             class="interpolation-image"-->
                <!--                             src="./static/images/interpolate_start.jpg"/>-->
                <!--                        <p>Start Frame</p>-->
                <!--                    </div>-->
                <!--                    <div class="column interpolation-video-column">-->
                <!--                        <div id="interpolation-image-wrapper">-->
                <!--                            Loading...-->
                <!--                        </div>-->
                <!--                        <input class="slider is-fullwidth is-large is-info"-->
                <!--                               id="interpolation-slider"-->
                <!--                               max="100" min="0" step="1" type="range" value="0">-->
                <!--                    </div>-->
                <!--                    <div class="column is-3 has-text-centered">-->
                <!--                        <img alt="Interpolation end reference image."-->
                <!--                             class="interpolation-image"-->
                <!--                             src="./static/images/interpolate_end.jpg"/>-->
                <!--                        <p class="is-bold">End Frame</p>-->
                <!--                    </div>-->
                <!--                </div>-->
                <!--                <br/>-->
                <!--                &lt;!&ndash;/ Interpolating. &ndash;&gt;-->

                <!-- movie_1 -->
                <h3 class="title is-4">A ROS2 package for robotic hand-eye calibration</h3>
                <div class="content has-text-justified">
                    <p>
                        Camera intrinsics can be obtained either from internal ROS2 topics or via our camera calibration
                        node.
                        This package also contains ROS2 nodes for aruco marker pose estimations, robot transformation
                        listener,
                        and OpenCV hand-eye calibration estimation. We presented a demo in simulation to explore the
                        accuracy of the algorithms.
                    </p>
                </div>
                <div class="content has-text-centered">
                    <video controls
                           id="movie_1"
                           muted
                           playsinline
                           preload
                           width="75%">
                        <source src="./static/videos/movie_1.mp4"
                                type="video/mp4">
                    </video>
                </div>
                <!--/ movie_1 -->
                <!-- movie_2 -->
                <h3 class="title is-4">Obstacle avoidance</h3>
                <div class="content has-text-justified">
                    <p>
                        Translating <span class="dnerf">cuRobo</span> using its python bindings and RTX 4060 GPU, we can
                        plan obstacle
                        -free, short and smooth path within 50 ms (cuboid) or 500 ms (cuboid + mesh). With RTX 4090, we
                        can reduce solve time
                        to 30 ms and 300 ms.
                    </p>
                </div>
                <div class="content has-text-centered">
                    <video controls
                           id="movie_2"
                           muted
                           playsinline
                           preload
                           width="75%">
                        <source src="./static/videos/movie_2.mp4"
                                type="video/mp4">
                    </video>
                </div>
                <!--/ movie_2 -->
                <!-- movie_3 -->
                <h3 class="title is-4">Object tracking performance</h3>
                <div class="content has-text-justified">
                    <p>
                        We demonstrated the robot’s ability to accurately follow both simple and complex predefined
                        motions,
                        with near-optimal, smooth paths.
                    </p>
                </div>
                <div class="content has-text-centered">
                    <video controls
                           id="movie_3"
                           muted
                           playsinline
                           preload
                           width="75%">
                        <source src="./static/videos/movie_3.mp4"
                                type="video/mp4">
                    </video>
                </div>
                <!--/ movie_3 -->
                <!-- movie_4 -->
                <h3 class="title is-4">Multi-robot system for collision-aware cotinuous tracking</h3>
                <div class="content has-text-justified">
                    <p>
                        The algorithms were applied in a multi-robot marker tracking experiment, with a demo showcasing
                        markerless knee tracking through collision-free paths.
                    </p>
                </div>
                <div class="content has-text-centered">
                    <video controls
                           id="movie_4"
                           muted
                           playsinline
                           preload
                           width="75%">
                        <source src="./static/videos/movie_4.mp4"
                                type="video/mp4">
                    </video>
                </div>
                <!--/ movie_4 -->

            </div>
        </div>
        <!--/ Animation. -->


        <!-- Concurrent Work. -->
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h2 class="title is-3">Related Links</h2>

                <div class="content has-text-justified">
                    <p>
                        KUKA LBR iiwa 7 ROS2 driver: <a href="https://github.com/lbr-stack/lbr_fri_ros2_stack">
                        lbr_fri_ros2_stack</a>
                    </p>
                    <p>
                        KUKA LBR iiwa14 ROS1 driver: <a href="https://github.com/IFL-CAMP/iiwa_stack"> iiwa_stack</a>
                    </p>
                    <p>
                        GPU-accelerated motion planning: <a href="https://curobo.org/"> cuRobo</a>
                    </p>
                </div>
            </div>
        </div>
        <!--/ Concurrent Work. -->

    </div>
</section>


<!--<section class="section" id="BibTeX">-->
<!--    <div class="container is-max-desktop content">-->
<!--        <h2 class="title">BibTeX</h2>-->
<!--        <pre><code>@article{park2021nerfies,-->
<!--  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},-->
<!--  title     = {Nerfies: Deformable Neural Radiance Fields},-->
<!--  journal   = {ICCV},-->
<!--  year      = {2021},-->
<!--}</code></pre>-->
<!--    </div>-->
<!--</section>-->


<footer class="footer">
    <div class="container">
        <!--        <div class="content has-text-centered">-->
        <!--            <a class="icon-link"-->
        <!--               href="./static/videos/nerfies_paper.pdf">-->
        <!--                <i class="fas fa-file-pdf"></i>-->
        <!--            </a>-->
        <!--            <a class="icon-link" class="external-link" disabled href="https://github.com/keunhong">-->
        <!--                <i class="fab fa-github"></i>-->
        <!--            </a>-->
        <!--        </div>-->

        <div class="content has-text-centered">
            <div class="column is-16">
                <div class="content">
                    <!--                    <p>-->
                    <!--                        This website is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/"-->
                    <!--                                                            rel="license">Creative-->
                    <!--                        Commons Attribution-ShareAlike 4.0 International License</a>.-->
                    <!--                    </p>-->
                    <!--                    <p>-->
                    <!--                        This means you are free to borrow the <a-->
                    <!--                            href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,-->
                    <!--                        we just ask that you link back to this page in the footer.-->
                    <!--                        Please remember to remove the analytics code included in the header of the website which-->
                    <!--                        you do not want on your website.-->
                    <!--                    </p>-->
                    <p>
                        &copy; Copyright <strong><span><a
                            href="https://shengyangzhuang.github.io/"> Shengyang Zhuang</a></span></strong> <br>
                        (First published: September 8, 2024; last updated: September 8, 2024)
                    </p>
                    <p>
                        Website taken from <a href="https://github.com/nerfies/nerfies.github.io">here</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>
