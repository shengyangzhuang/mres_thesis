<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta content="Multi-Robot System Prototyping for Cooperative Control in Robot-Assisted Spine Surgery"
          name="description">
    <meta content="Robotics, cuRobo, markerless tracking" name="keywords">
    <meta content="width=device-width, initial-scale=1" name="viewport">
    <title>Multi-Robot System Prototyping for Cooperative Control in Robot-Assisted Spine Surgery</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
          dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link href="./static/css/bulma.min.css" rel="stylesheet">
    <link href="./static/css/bulma-carousel.min.css" rel="stylesheet">
    <link href="./static/css/bulma-slider.min.css" rel="stylesheet">
    <link href="./static/css/fontawesome.all.min.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
          rel="stylesheet">
    <link href="./static/css/index.css" rel="stylesheet">
    <link href="./static/images/favicon.svg" rel="icon">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>
<body>

<!--<nav class="navbar" role="navigation" aria-label="main navigation">-->
<!--  <div class="navbar-brand">-->
<!--    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">-->
<!--      <span aria-hidden="true"></span>-->
<!--      <span aria-hidden="true"></span>-->
<!--      <span aria-hidden="true"></span>-->
<!--    </a>-->
<!--  </div>-->
<!--  <div class="navbar-menu">-->
<!--    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">-->
<!--      <a class="navbar-item" href="https://keunhong.com">-->
<!--      <span class="icon">-->
<!--          <i class="fas fa-home"></i>-->
<!--      </span>-->
<!--      </a>-->

<!--      <div class="navbar-item has-dropdown is-hoverable">-->
<!--        <a class="navbar-link">-->
<!--          More Research-->
<!--        </a>-->
<!--        <div class="navbar-dropdown">-->
<!--          <a class="navbar-item" href="https://hypernerf.github.io">-->
<!--            HyperNeRF-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://nerfies.github.io">-->
<!--            Nerfies-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://latentfusion.github.io">-->
<!--            LatentFusion-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://photoshape.github.io">-->
<!--            PhotoShape-->
<!--          </a>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->

<!--  </div>-->
<!--</nav>-->


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">Multi-Robot System Prototyping for Cooperative Control in
                        Robot-Assisted Spine Surgery</h1>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">
                          <a href="https://shengyangzhuang.github.io/">Shengyang Zhuang</a><!--<sup>1</sup>-->,</span>
                        <span class="author-block">
                          <a href="https://www.linkedin.com/in/connor-daly-595648114/">Connor Daly</a>,</span>
                        <span class="author-block">
                          <a href="https://profiles.imperial.ac.uk/hisham.iqbal13">Hisham Iqbal</a>, and
                        </span>
                        <span class="author-block">
                          <a href="https://profiles.imperial.ac.uk/f.rodriguez">Ferdinando Rodriguez y Baena</a>
                        </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block">Mechatronics in Medicine Lab, The Hamlyn Centre for Robotic Surgery, Imperial College London</span>
                        <!-- <span class="author-block"><sup>2</sup>Google Research</span> -->
                    </div>

                                        <div class="column has-text-centered">
                                            <div class="publication-links">
                    <!--                            &lt;!&ndash; PDF Link. &ndash;&gt;-->
                    <!--                            <span class="link-block">-->
                    <!--                                <a class="external-link button is-normal is-rounded is-dark"-->
                    <!--                                   href="https://arxiv.org/pdf/2011.12948">-->
                    <!--                                  <span class="icon">-->
                    <!--                                      <i class="fas fa-file-pdf"></i>-->
                    <!--                                  </span>-->
                    <!--                                  <span>Paper</span>-->
                    <!--                                </a>-->
                    <!--                            </span>-->
                    <!--                            <span class="link-block">-->
                    <!--                                <a class="external-link button is-normal is-rounded is-dark"-->
                    <!--                                   href="https://arxiv.org/abs/2011.12948">-->
                    <!--                                  <span class="icon">-->
                    <!--                                      <i class="ai ai-arxiv"></i>-->
                    <!--                                  </span>-->
                    <!--                                  <span>arXiv</span>-->
                    <!--                                </a>-->
                    <!--                            </span>-->
                                                <!-- Video Link. -->
                                                <span class="link-block">
                                                    <a class="external-link button is-normal is-rounded is-dark"
                                                       href="https://youtu.be/JFW1dwNRHys">
                                                      <span class="icon">
                                                          <i class="fab fa-youtube"></i>
                                                      </span>
                                                      <span>Video</span>
                                                    </a>
                                                </span>
                                                <!-- Code Link. -->
                                                <span class="link-block">
                                                    <a class="external-link button is-normal is-rounded is-dark"
                                                       href="https://github.com/shengyangzhuang/mres_thesis">
                                                      <span class="icon">
                                                          <i class="fab fa-github"></i>
                                                      </span>
                                                      <span>Code</span>
                                                      </a>
                                                </span>
<!--                                                &lt;!&ndash; Dataset Link. &ndash;&gt;-->
<!--                                                <span class="link-block">-->
<!--                                                    <a class="external-link button is-normal is-rounded is-dark"-->
<!--                                                       href="https://github.com/google/nerfies/releases/tag/0.1">-->
<!--                                                      <span class="icon">-->
<!--                                                          <i class="far fa-images"></i>-->
<!--                                                      </span>-->
<!--                                                      <span>Data</span>-->
<!--                                                      </a>-->
<!--                                                </span>-->
                                            </div>
                                        </div>

                </div>
            </div>
        </div>
    </div>
</section>

<!--<section class="hero teaser">-->
<!--  <div class="container is-max-desktop">-->
<!--    <div class="hero-body">-->
<!--      <video id="teaser" autoplay muted loop playsinline height="100%">-->
<!--        <source src="./static/videos/teaser.mp4"-->
<!--                type="video/mp4">-->
<!--      </video>-->
<!--      <h2 class="subtitle has-text-centered">-->
<!--        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into-->
<!--        free-viewpoint-->
<!--        portraits.-->
<!--      </h2>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->


<!--<section class="hero is-light is-small">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <div id="results-carousel" class="carousel results-carousel">-->
<!--        <div class="item item-steve">-->
<!--          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/steve.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-chair-tp">-->
<!--          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/chair-tp.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-shiba">-->
<!--          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/shiba.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-fullbody">-->
<!--          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/fullbody.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-blueshirt">-->
<!--          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/blueshirt.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-mask">-->
<!--          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/mask.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-coffee">-->
<!--          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/coffee.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-toby">-->
<!--          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/toby2.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->


<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Robot-assisted spine surgery has been clinically validated worldwide, demonstrating enhanced
                        performance, efficiency, and safety. However, current spine robotic systems rely on fiducial
                        markers, requiring additional incisions that increase the risk of infection. Additionally,
                        optical tracking systems are susceptible to line-of-sight obstructions. Previous research has
                        demonstrated limitations in simplifying obstacles as single points, making complex obstacle
                        environments unmanageable.
                    </p>
                    <p>
                        In this thesis, a multi-robot cooperative platform for surgery was developed, featuring a
                        plug-in to integrate a markerless depth image segmentation network for globally optimal
                        collision-free object tracking. The system enables a tracking robot arm to automatically adjust
                        its pose to maintain visual contact with a moving target, while the second surgical robot arm
                        acts as an obstacle. To achieve this, precise hand-eye calibration algorithms, including camera
                        calibration and ArUco marker detection, were developed with ROS2. Its accuracy was assessed in a
                        simulation environment before being tested on the real robot. The state-of-the-art cuRobo, a
                        GPU-accelerated motion planning library, was translated by developing ROS2 packages for highly
                        parallel inverse kinematics and trajectory optimization. Leveraging parallel computing enables
                        realizing a global optimal solution for obstacle avoidance. The motion-tracking performance of
                        the real robot on the generated trajectory was analyzed. Separate experiments and solve time
                        analyses were conducted for both simple and complex obstacle avoidance scenarios. The pipeline
                        was further developed into a continuous, efficient, collision-free object-tracking system. A
                        tracking performance analysis showed that the system generated near-optimal, smooth, and
                        collision-free paths. Finally, the algorithms were applied in a multi-robot marker tracking
                        experiment, with a demo showcasing markerless knee tracking through collision-free paths.
                    </p>
                </div>
            </div>
        </div>
        <!--/ Abstract. -->

        <!-- Paper video. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Video</h2>
                <div class="publication-video">
                    <iframe allow="autoplay; encrypted-media"
                            allowfullscreen frameborder="0" src="https://www.youtube.com/embed/JFW1dwNRHys?si=Xa80sG6w1l3x6M2j"></iframe>
                </div>
            </div>
        </div>
        <!--/ Paper video. -->
    </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column">
                <div class="content">
                    <h2 class="title is-3">Robotic Hand-Eye Calibration</h2>
                    <h3 class="title is-4">Simulation of hand-eye calibration</h3>
                    <p>
                        The algorithm was tested in simulation, where the ground truth was known.
                    </p>
                    <div class="columns is-vcentered interpolation-panel">
                        <!-- First video -->
                        <div class="column">
                            <video autoplay height="100%" id="sim_positions" loop muted playsinline>
                                <source src="./static/videos/sim_positions.mp4" type="video/mp4">
                            </video>
                        </div>
                        <!-- Second video -->
                        <div class="column">
                            <video autoplay height="100%" id="sim_profile" loop muted playsinline>
                                <source src="./static/videos/sim_profile.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <h3 class="title is-4">Experiment with RealSense D415, KUKA LBR iiwa 7 (LBR-stack ROS2 driver)</h3>
                    <p>
                        Then similar robot and marker poses were repeated in real experiments to ensure accuracy.
                    </p>
                    <div class="columns is-vcentered interpolation-panel">
                        <!-- First video -->
                        <div class="column">
                            <video autoplay height="100%" id="real_positions" loop muted playsinline>
                                <source src="./static/videos/real_positions.mp4" type="video/mp4">
                            </video>
                        </div>
                        <!-- Second video -->
                        <div class="column">
                            <video autoplay height="100%" id="handeye_calculation" loop muted playsinline>
                                <source src="./static/videos/handeye_calculation.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
                <br>
                <div class="content">
                    <h2 class="title is-3">Collision-Aware Robotics Platform for Tracking</h2>
                    <h3 class="title is-4">Comparison between curobo and RRTConnect (MoveIt default planner)</h3>
                    <div class="columns is-vcentered interpolation-panel">
                        <!-- First video -->
                        <div class="column">
                            <video autoplay height="100%" id="curobo" loop muted playsinline>
                                <source src="./static/videos/curobo.mp4" type="video/mp4">
                            </video>
                        </div>
                        <!-- Second video -->
                        <div class="column">
                            <video autoplay height="100%" id="rrt" loop muted playsinline>
                                <source src="./static/videos/rrt.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <h3 class="title is-4">Tracking performance analysis</h3>
                    <p>
                        LBR iiwa 14 held a marker with pre-defined motion (straight line and Imperial 'I'), while iiwa 7 tracked the motion. Result
                        demonstrated the robot's ability to follow both simple and complex patterns, with short and smooth paths.
                    </p>
                    <div class="columns is-vcentered interpolation-panel">
                        <!-- First video -->
                        <div class="column">
                            <video autoplay height="100%" id="line" loop muted playsinline>
                                <source src="./static/videos/line_tracking.mp4" type="video/mp4">
                            </video>
                        </div>
                        <!-- Second video -->
                        <div class="column">
                            <video autoplay height="100%" id="i" loop muted playsinline>
                                <source src="./static/videos/i_tracking.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <p>
                        More accurate end-effector traces were visualized. The arrow represents the orientation of the waypoint.
                    </p>
                    <div class="columns is-vcentered interpolation-panel">
                        <!-- First video -->
                        <div class="column">
                            <video autoplay height="100%" id="line2" loop muted playsinline>
                                <source src="./static/videos/line_trace.mp4" type="video/mp4">
                            </video>
                        </div>
                        <!-- Second video -->
                        <div class="column">
                            <video autoplay height="100%" id="i2" loop muted playsinline>
                                <source src="./static/videos/i_trace.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <h3 class="title is-4">Multi-Robot System for Continuous tracking</h3>
                    <div class="columns is-vcentered interpolation-panel">
                        <!-- First video -->
                        <div class="column">
                            <video autoplay height="100%" id="marker" loop muted playsinline>
                                <source src="./static/videos/marker.mp4" type="video/mp4">
                            </video>
                        </div>
                        <!-- Second video -->
                        <div class="column">
                            <video autoplay height="100%" id="knee" loop muted playsinline>
                                <source src="./static/videos/knee.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <!-- Animation. -->
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h2 class="title is-2">Supplementary videos</h2>
                <!-- movie_1 -->
                <h3 class="title is-4">A ROS2 package for robotic hand-eye calibration</h3>
                <div class="content has-text-justified">
                    <p>
                        Camera intrinsics can be obtained either from internal ROS2 topics or via our camera calibration
                        node.
                        This package also contains ROS2 nodes for aruco marker pose estimations, robot transformation
                        listener,
                        and OpenCV hand-eye calibration estimation. We presented a demo in simulation to explore the
                        accuracy of the algorithms.
                    </p>
                </div>
                <div class="content has-text-centered">
                    <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen
                            frameborder="0"
                            height="400"
                            src="https://www.youtube.com/embed/EUSxnzzP8qk?si=n9UmxZwSEPIp4dj0"
                            title="YouTube video player"
                            width="75%">
                    </iframe>
                </div>
                <!--/ movie_1 -->
                <!-- movie_2 -->
                <h3 class="title is-4">Obstacle avoidance</h3>
                <div class="content has-text-justified">
                    <p>
                        Translating <span class="dnerf">cuRobo</span> using its python bindings and RTX 4060 GPU, we can
                        plan obstacle
                        -free, short and smooth path within 50 ms (cuboid) or 500 ms (cuboid + mesh). With RTX 4090, we
                        can reduce solve time to 30 ms and 300 ms. Representing the obstacle robot as spheres further
                        reduces solve time (under development).
                    </p>
                </div>
                <div class="content has-text-centered">
                    <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen
                            frameborder="0"
                            height="400"
                            src="https://www.youtube.com/embed/Ozlj8U36q20?si=UL6uciLbsxHo1gcO"
                            title="YouTube video player"
                            width="75%">
                    </iframe>
                </div>
                <!--/ movie_2 -->
                <!-- movie_3 -->
                <h3 class="title is-4">Object tracking performance</h3>
                <div class="content has-text-justified">
                    <p>
                        We demonstrated the robot’s ability to accurately follow both simple and complex predefined
                        motions,
                        with near-optimal, smooth paths.
                    </p>
                </div>
                <div class="content has-text-centered">
                    <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen
                            frameborder="0"
                            height="400"
                            src="https://www.youtube.com/embed/3yXkwlKCoOk?si=OIm-12tTgByktHhi"
                            title="YouTube video player"
                            width="75%">
                    </iframe>
                </div>
                <!--/ movie_3 -->
                <!-- movie_4 -->
                <h3 class="title is-4">Multi-robot system for collision-aware cotinuous tracking</h3>
                <div class="content has-text-justified">
                    <p>
                        The algorithms were applied in a multi-robot marker tracking experiment, with a demo showcasing
                        markerless knee tracking through collision-free paths.
                    </p>
                </div>
                <div class="content has-text-centered">
                    <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen
                            frameborder="0"
                            height="400"
                            src="https://www.youtube.com/embed/4WYj4uP97l4?si=PQHPBSFsBbdIl7P6"
                            title="YouTube video player"
                            width="75%">
                    </iframe>
                </div>
                <!--/ movie_4 -->

            </div>
        </div>
        <!--/ Animation. -->


        <!-- Concurrent Work. -->
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h2 class="title is-3">Related Links</h2>

                <div class="content has-text-justified">
                    <p>
                        KUKA LBR iiwa 7 ROS2 driver: <a href="https://github.com/lbr-stack/lbr_fri_ros2_stack">
                        lbr_fri_ros2_stack</a>
                    </p>
                    <p>
                        KUKA LBR iiwa14 ROS1 driver: <a href="https://github.com/IFL-CAMP/iiwa_stack"> iiwa_stack</a>
                    </p>
                    <p>
                        GPU-accelerated motion planning: <a href="https://curobo.org/"> cuRobo</a>
                    </p>
                </div>
            </div>
        </div>
        <!--/ Concurrent Work. -->

    </div>
</section>


<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@mastersthesis{zhuang2024multirobot,
  author    = {Zhuang, Shengyang},
  title     = {Multi-Robot System Prototyping for Cooperative Control in Robot-Assisted Spine Surgery},
  school    = {Imperial College London},
  year      = {2024},
}</code></pre>
    </div>
</section>


<footer class="footer">
    <div class="container">
        <!--        <div class="content has-text-centered">-->
        <!--            <a class="icon-link"-->
        <!--               href="./static/videos/nerfies_paper.pdf">-->
        <!--                <i class="fas fa-file-pdf"></i>-->
        <!--            </a>-->
        <!--            <a class="icon-link" class="external-link" disabled href="https://github.com/keunhong">-->
        <!--                <i class="fab fa-github"></i>-->
        <!--            </a>-->
        <!--        </div>-->

        <div class="content has-text-centered">
            <div class="column is-16">
                <div class="content">
                    <!--                    <p>-->
                    <!--                        This website is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/"-->
                    <!--                                                            rel="license">Creative-->
                    <!--                        Commons Attribution-ShareAlike 4.0 International License</a>.-->
                    <!--                    </p>-->
                    <!--                    <p>-->
                    <!--                        This means you are free to borrow the <a-->
                    <!--                            href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,-->
                    <!--                        we just ask that you link back to this page in the footer.-->
                    <!--                        Please remember to remove the analytics code included in the header of the website which-->
                    <!--                        you do not want on your website.-->
                    <!--                    </p>-->
                    <p>
                        &copy; Copyright <strong><span><a
                            href="https://shengyangzhuang.github.io/"> Shengyang Zhuang</a></span></strong> <br>
                        (First published: September 8, 2024; last updated: September 9, 2024)
                    </p>
                    <p>
                        Website taken from <a href="https://github.com/nerfies/nerfies.github.io">here</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>
